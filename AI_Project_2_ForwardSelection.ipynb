{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import Libraries For Helper Functions"
      ],
      "metadata": {
        "id": "FQkvYNVXHRlt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "AumfBDqfDKOX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def distEuclidean(firstVec, secondVec, columns):\n",
        "    distance = 0\n",
        "    for i in columns:\n",
        "        distance += (firstVec[i] - secondVec[i]) ** 2\n",
        "    return np.sqrt(distance)"
      ],
      "metadata": {
        "id": "5biirrVgNSXX"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ZScoreNormalization(features):\n",
        "  mean = np.mean(features)\n",
        "  stdDev = np.std(features)\n",
        "  data = (features - mean) / stdDev\n",
        "  return data"
      ],
      "metadata": {
        "id": "ZqeOwbRKKfI-"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forwardSelection(data):\n",
        "    #print(len(data), len(data[0]))\n",
        "    dataset = ZScoreNormalization(data) #ZScore Normalization, Mean = 0, Standard Deviation = 1\n",
        "    #print(dataset)\n",
        "    bestSoFar = 0.0\n",
        "    bestFeatureSet = set()\n",
        "    currFeatureSet = set()\n",
        "    #loops once outer for each feature\n",
        "    for i in range(1, len(dataset[0])):\n",
        "        print(f\"Best Accuracy and Features until now: {bestSoFar*100:.2f}% {bestFeatureSet} \") # Checkpointing\n",
        "        print(f\"Currently evaluating level {i} of the search tree\")\n",
        "        currentBest = 0\n",
        "        featureToAdd = None\n",
        "        #loops same number of times for during each outer loop\n",
        "        for feature in range(1, len(dataset[0])):\n",
        "            if feature not in currFeatureSet:\n",
        "                print(\"Consider Adding feature:\", feature)\n",
        "                tempFeatures = list(currFeatureSet) #temporary copy\n",
        "                tempFeatures.append(feature) #adding newest entry and testing how that affects accuracy in the search\n",
        "                correctClassification = 0 #successful classifications\n",
        "                minDist = math.inf # To find minimum distance\n",
        "                y_pred = 0\n",
        "                #applying the Euclidean distance function to each row's comparison as a vector\n",
        "                for row1 in dataset:\n",
        "                    minDist = math.inf\n",
        "                    for row2 in dataset:\n",
        "                        duplicate = (row1 == row2).all()\n",
        "                        if not duplicate:\n",
        "                            value = distEuclidean(row1 , row2, tempFeatures)\n",
        "                            if value < minDist:\n",
        "                                minDist = value\n",
        "                                prediction_class = row2[0]\n",
        "                    if prediction_class == row1[0]:\n",
        "                        correctClassification += 1\n",
        "                accuracy = correctClassification / (len(dataset) )  #measuring accuracy\n",
        "\n",
        "                # determining if recently-stored correctness needs to be updated so that it reflects both globally and in the current working copy.\n",
        "                if accuracy > currentBest:\n",
        "                    currentBest = accuracy\n",
        "                    featureToAdd = feature\n",
        "        currFeatureSet.add(featureToAdd)\n",
        "        print(f\"At iteration {i} we added feature {featureToAdd} to current set\")\n",
        "        print(f\"Using feature(s) {currFeatureSet} the accuracy is {currentBest*100:.2f}%\")\n",
        "        if featureToAdd and currentBest > bestSoFar:  #print operatings to display progress and results\n",
        "              print(f\"From {bestSoFar*100:.2f}%\")\n",
        "              bestSoFar = currentBest\n",
        "              print(f\"To {bestSoFar*100:.2f}%\")\n",
        "              print(\"******************************\")\n",
        "              bestFeatureSet = set(currFeatureSet)\n",
        "\n",
        "    print(f\"Finished Search!! The complete best feature subset is {bestFeatureSet} which has an accuracy of {bestSoFar*100:.2f}%\")"
      ],
      "metadata": {
        "id": "EpnMCttJKW0i"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\"\"Feature Selection\\n\"\"\")\n",
        "\n",
        "fileChoice = int(input(\"Data File to be used: 1: CS170_small_Data__20.txt, 2: CS170_large_Data__1.txt, 3: CS170_XXXLarge_Data__11.txt\\n\"))\n",
        "algo = int(input(\"\"\"\\nAlgorithm \\n\n",
        "1. Forward Selection \\n\n",
        "2. Backward Elimination \\n\"\"\" ))\n",
        "\n",
        "file = None\n",
        "if fileChoice == 2:\n",
        "  file = \"CS170_large_Data__1.txt\"\n",
        "elif fileChoice == 3:\n",
        "  file = \"CS170_XXXLarge_Data__11.txt\"\n",
        "else:\n",
        "  file = \"CS170_small_Data__20.txt\"\n",
        "\n",
        "try:\n",
        "    with open(file) as d:\n",
        "        data = pd.read_csv(file, delim_whitespace=True)\n",
        "        dataLen = data.shape[0]\n",
        "        loadDataset = np.loadtxt(file)\n",
        "except:\n",
        "    print(\"Error Loading File. Re-run and try again.\")\n",
        "\n",
        "# printing dataset details\n",
        "print(f\"\\nData contains {len(loadDataset[0]) - 1} features with {dataLen + 1} samples \")\n",
        "print(\"Beginning Search\")\n",
        "if algo == 1:\n",
        "    forwardSelection(loadDataset)"
      ],
      "metadata": {
        "id": "VcHm1IFU0KYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bacb91b5-ec24-448d-b237-bf296ede395d"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Selection\n",
            "\n",
            "Data File to be used: 1: CS170_small_Data__20.txt, 2: CS170_large_Data__1.txt, 3: CS170_XXXLarge_Data__11.txt\n",
            "1\n",
            "\n",
            "Algorithm \n",
            " \n",
            "1. Forward Selection \n",
            "\n",
            "2. Backward Elimination \n",
            "1\n",
            "\n",
            "Data contains 10 features with 1000 samples \n",
            "Beginning Search\n",
            "Best Accuracy and Features until now: 0.00% set() \n",
            "Currently evaluating level 1 of the search tree\n",
            "Consider Adding feature: 1\n",
            "Consider Adding feature: 2\n",
            "Consider Adding feature: 3\n",
            "Consider Adding feature: 4\n",
            "Consider Adding feature: 5\n",
            "Consider Adding feature: 6\n",
            "Consider Adding feature: 7\n",
            "Consider Adding feature: 8\n",
            "Consider Adding feature: 9\n",
            "Consider Adding feature: 10\n",
            "At iteration 1 we added feature 5 to current set\n",
            "Using feature(s) {5} the accuracy is 85.70%\n",
            "From 0.00%\n",
            "To 85.70%\n",
            "******************************\n",
            "Best Accuracy and Features until now: 85.70% {5} \n",
            "Currently evaluating level 2 of the search tree\n",
            "Consider Adding feature: 1\n",
            "Consider Adding feature: 2\n",
            "Consider Adding feature: 3\n",
            "Consider Adding feature: 4\n",
            "Consider Adding feature: 6\n",
            "Consider Adding feature: 7\n",
            "Consider Adding feature: 8\n",
            "Consider Adding feature: 9\n",
            "Consider Adding feature: 10\n",
            "At iteration 2 we added feature 7 to current set\n",
            "Using feature(s) {5, 7} the accuracy is 96.30%\n",
            "From 85.70%\n",
            "To 96.30%\n",
            "******************************\n",
            "Best Accuracy and Features until now: 96.30% {5, 7} \n",
            "Currently evaluating level 3 of the search tree\n",
            "Consider Adding feature: 1\n",
            "Consider Adding feature: 2\n",
            "Consider Adding feature: 3\n",
            "Consider Adding feature: 4\n",
            "Consider Adding feature: 6\n",
            "Consider Adding feature: 8\n",
            "Consider Adding feature: 9\n",
            "Consider Adding feature: 10\n",
            "At iteration 3 we added feature 1 to current set\n",
            "Using feature(s) {1, 5, 7} the accuracy is 95.00%\n",
            "Best Accuracy and Features until now: 96.30% {5, 7} \n",
            "Currently evaluating level 4 of the search tree\n",
            "Consider Adding feature: 2\n",
            "Consider Adding feature: 3\n",
            "Consider Adding feature: 4\n",
            "Consider Adding feature: 6\n",
            "Consider Adding feature: 8\n",
            "Consider Adding feature: 9\n",
            "Consider Adding feature: 10\n",
            "At iteration 4 we added feature 9 to current set\n",
            "Using feature(s) {1, 5, 9, 7} the accuracy is 92.00%\n",
            "Best Accuracy and Features until now: 96.30% {5, 7} \n",
            "Currently evaluating level 5 of the search tree\n",
            "Consider Adding feature: 2\n",
            "Consider Adding feature: 3\n",
            "Consider Adding feature: 4\n",
            "Consider Adding feature: 6\n",
            "Consider Adding feature: 8\n",
            "Consider Adding feature: 10\n",
            "At iteration 5 we added feature 4 to current set\n",
            "Using feature(s) {1, 4, 5, 7, 9} the accuracy is 88.60%\n",
            "Best Accuracy and Features until now: 96.30% {5, 7} \n",
            "Currently evaluating level 6 of the search tree\n",
            "Consider Adding feature: 2\n",
            "Consider Adding feature: 3\n",
            "Consider Adding feature: 6\n",
            "Consider Adding feature: 8\n",
            "Consider Adding feature: 10\n",
            "At iteration 6 we added feature 8 to current set\n",
            "Using feature(s) {1, 4, 5, 7, 8, 9} the accuracy is 86.40%\n",
            "Best Accuracy and Features until now: 96.30% {5, 7} \n",
            "Currently evaluating level 7 of the search tree\n",
            "Consider Adding feature: 2\n",
            "Consider Adding feature: 3\n",
            "Consider Adding feature: 6\n",
            "Consider Adding feature: 10\n",
            "At iteration 7 we added feature 6 to current set\n",
            "Using feature(s) {1, 4, 5, 6, 7, 8, 9} the accuracy is 83.40%\n",
            "Best Accuracy and Features until now: 96.30% {5, 7} \n",
            "Currently evaluating level 8 of the search tree\n",
            "Consider Adding feature: 2\n",
            "Consider Adding feature: 3\n",
            "Consider Adding feature: 10\n",
            "At iteration 8 we added feature 2 to current set\n",
            "Using feature(s) {1, 2, 4, 5, 6, 7, 8, 9} the accuracy is 81.90%\n",
            "Best Accuracy and Features until now: 96.30% {5, 7} \n",
            "Currently evaluating level 9 of the search tree\n",
            "Consider Adding feature: 3\n",
            "Consider Adding feature: 10\n",
            "At iteration 9 we added feature 3 to current set\n",
            "Using feature(s) {1, 2, 3, 4, 5, 6, 7, 8, 9} the accuracy is 81.40%\n",
            "Best Accuracy and Features until now: 96.30% {5, 7} \n",
            "Currently evaluating level 10 of the search tree\n",
            "Consider Adding feature: 10\n",
            "At iteration 10 we added feature 10 to current set\n",
            "Using feature(s) {1, 2, 3, 4, 5, 6, 7, 8, 9, 10} the accuracy is 78.80%\n",
            "Finished Search!! The complete best feature subset is {5, 7} which has an accuracy of 96.30%\n"
          ]
        }
      ]
    }
  ]
}